{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.metrics import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_comentario_total = pd.read_table('train.tsv',usecols=[0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_comentarios_treinamento,base_comentarios_teste=train_test_split(base_comentario_total,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_comentarios_treinamento_lista=[]\n",
    "for i in range(0,7000):\n",
    "    base_comentarios_treinamento_lista.append([str(base_comentarios_treinamento.values[i,j]) for  j in range(1,3)])\n",
    "\n",
    "\n",
    "base_comentarios_teste_lista=[]\n",
    "for i in range(0,1500):\n",
    "    base_comentarios_teste_lista.append([str(base_comentarios_teste.values[i,j]) for  j in range(1,3)])\n",
    "\n",
    "\n",
    "\n",
    "base_comentario_predicao,base_comentarios_teste=train_test_split(base_comentarios_teste,test_size=0.5)\n",
    "\n",
    "tamanho_predicao=len(base_comentario_predicao)\n",
    "\n",
    "\n",
    "base_comentario_predicao_lista=[]\n",
    "for i in range(0,1500):\n",
    "    base_comentario_predicao_lista.append([str(base_comentario_predicao.values[i,j]) for j in range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordscompleto = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "def RetirarStopWordsRadical(texto):\n",
    "    radical=nltk.stem.SnowballStemmer('english')\n",
    "    frasesSemRadical = []\n",
    "    for (Phrase,Sentiment) in texto:\n",
    "        FraseLimpa=[str(radical.stem(p)) for p in Phrase.split()  if p not in stopwordscompleto]\n",
    "#        FraseLimpa=[str(radical.stem(p)) for p in Phrase.split()]\n",
    "        frasesSemRadical.append((FraseLimpa,Sentiment))\n",
    "    return frasesSemRadical\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FrasesTreinamentoSemRadical =RetirarStopWordsRadical(base_comentarios_treinamento_lista)\n",
    "FrasestesteSemRadical =RetirarStopWordsRadical(base_comentarios_teste_lista)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######PALAVRAS UNICAS\n",
    "def buscapalavras(frases):\n",
    "    todaspalavras=[]\n",
    "    for (Phrase,Sentiment) in frases:\n",
    "        todaspalavras.extend(Phrase)\n",
    "    return todaspalavras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "palavrasTreinamento = buscapalavras(FrasesTreinamentoSemRadical)\n",
    "palavrasTeste = buscapalavras(FrasestesteSemRadical)\n",
    "\n",
    "#####CONTABILIZANDO A FREQUENCIA DOS RADICAIS\n",
    "def buscafrequencia(palavras):\n",
    "    palavras=nltk.FreqDist(palavras)\n",
    "    return palavras\n",
    "\n",
    "\n",
    "frequenciaTreinamento = buscafrequencia(palavrasTreinamento)\n",
    "frequenciaTeste = buscafrequencia(palavrasTeste)\n",
    "\n",
    "#############PALAVRAS UNICAS\n",
    "def buscapalavrasunicas(frequencia):\n",
    "    freq=frequencia.keys()\n",
    "    return freq\n",
    "\n",
    "palavrasunicasTreinamento=buscapalavrasunicas(frequenciaTreinamento)\n",
    "palavrasunicasTeste=buscapalavrasunicas(frequenciaTeste)\n",
    "\n",
    "\n",
    "###RETORNAR EXTRATOR DE PALAVRAS\n",
    "def extratorpalavrasTreinamento(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicasTreinamento={}\n",
    "    for palavras in palavrasunicasTreinamento:\n",
    "        caracteristicasTreinamento['%s' % palavras]=(palavras in doc)\n",
    "    return caracteristicasTreinamento\n",
    "\n",
    "\n",
    "def extratorpalavrasTeste(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicasTeste={}\n",
    "    for palavras in palavrasunicasTeste:\n",
    "        caracteristicasTeste['%s' % palavras]=(palavras in doc)\n",
    "    return caracteristicasTeste\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#caracteristicasfrase = extratorpalavras()\n",
    "\n",
    "basecompletaTreinamento = nltk.classify.apply_features(extratorpalavrasTreinamento,FrasesTreinamentoSemRadical)\n",
    "basecompletaTeste = nltk.classify.apply_features(extratorpalavrasTeste,FrasestesteSemRadical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5386666666666666\n"
     ]
    }
   ],
   "source": [
    "classificador = nltk.NaiveBayesClassifier.train(basecompletaTreinamento) ##constroi as tabelas de probabilidade\n",
    "\n",
    "acuracia=nltk.classify.accuracy(classificador,basecompletaTeste)\n",
    "print(nltk.classify.accuracy(classificador,basecompletaTeste)) #acuracia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscapalavrasPredicao(frases):\n",
    "    todaspalavras=[]\n",
    "    for (Phrase) in frases:\n",
    "        todaspalavras.extend(FrasesPredicaoSemRadical)\n",
    "    return todaspalavras\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stopwordscompleto = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "for sentenca in base_comentario_predicao_lista:\n",
    "    Phrase = sentenca[1]\n",
    "#    print(Phrase)\n",
    "    \n",
    "    radical=nltk.stem.SnowballStemmer('english')\n",
    "    frasesSemRadicalPredicao = []\n",
    "#    FrasesPredicaoSemRadical=[str(radical.stem(p)) for p in Phrase.split()]\n",
    "    FrasesPredicaoSemRadical=[str(radical.stem(p)) for p in Phrase.split()  if p not in stopwordscompleto]\n",
    "    #print(FrasesPredicaoSemRadical)\n",
    "    \n",
    "    palavrasTestePredicao=buscapalavrasPredicao(FrasesPredicaoSemRadical)\n",
    "    #print(palavrasTestePredicao)\n",
    "    \n",
    "    \n",
    "    FrequenciaPredicao = nltk.FreqDist(palavrasTestePredicao)\n",
    "    #print(FrequenciaPredicao)\n",
    "    \n",
    "    \n",
    "    palavraunicasPredicao=FrequenciaPredicao.keys()\n",
    "    #print(palavraunicasPredicao)\n",
    "    \n",
    "    \n",
    "    def extratorpalavrasPredicao(documento):\n",
    "        doc = set(documento)\n",
    "        caracteristicasPredicao={}\n",
    "        for palavras in palavraunicasPredicao:\n",
    "            caracteristicasPredicao['%s' % palavras]=(palavras in doc)\n",
    "        return caracteristicasPredicao\n",
    "    \n",
    "    basecompletaPredicao =   extratorpalavrasPredicao(palavraunicasPredicao)\n",
    "    resultado=sentenca[0]+','+classificador.classify(basecompletaPredicao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5386666666666666\n",
      "  |   0   1   2   3   4 |\n",
      "--+---------------------+\n",
      "0 | <12> 27  20   2   3 |\n",
      "1 |  32 <64>138  25   7 |\n",
      "2 |   7  66<612> 62  20 |\n",
      "3 |  11  25 146 <97> 34 |\n",
      "4 |   7   2  26  32 <23>|\n",
      "--+---------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################MONTANDO A MATRIZ DE CONFUSAO\n",
    "acuracia1=nltk.classify.accuracy(classificador,basecompletaTeste)\n",
    "print(nltk.classify.accuracy(classificador,basecompletaTeste)) #acuracia\n",
    "\n",
    "esperado=[]\n",
    "previsto=[]\n",
    "for (Phrases,Sentiment) in basecompletaTeste:\n",
    "    resultado=classificador.classify(Phrases)\n",
    "    previsto.append(resultado)\n",
    "    esperado.append(Sentiment)\n",
    "\n",
    "\n",
    "#print(pre//////////////////visto)\n",
    "#print(esperado)\n",
    "\n",
    "matriz = ConfusionMatrix(esperado,previsto)\n",
    "print(matriz)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
